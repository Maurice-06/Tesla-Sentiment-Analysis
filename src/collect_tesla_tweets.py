"""
Phase 1 - Data Engineering : Collecte de tweets Tesla avec Tweepy

Ce module collecte les tweets r√©cents concernant Tesla depuis l'API Twitter v2.
Il g√®re les rate limits, filtre les retweets et sauvegarde les donn√©es brutes.
"""

import os
import sys

# Workaround pour imghdr supprim√© dans Python 3.13+
if sys.version_info >= (3, 13):
    import importlib.util
    spec = importlib.util.spec_from_file_location("imghdr", os.path.join(os.path.dirname(__file__), "imghdr_compat.py"))
    imghdr = importlib.util.module_from_spec(spec)
    sys.modules["imghdr"] = imghdr
    spec.loader.exec_module(imghdr)

import tweepy
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv
from typing import List, Dict, Optional
import time

# Charger les variables d'environnement
load_dotenv()


class TeslaTweetCollector:
    """
    Classe pour collecter des tweets sur Tesla via l'API Twitter.
    
    G√®re l'authentification, la collecte avec pagination, et la sauvegarde
    des donn√©es en CSV.
    """
    
    def __init__(self, bearer_token: Optional[str] = None):
        """
        Initialise le collecteur avec les credentials Twitter.
        
        Args:
            bearer_token: Token Bearer pour l'API v2 (ou depuis .env)
        """
        self.bearer_token = bearer_token or os.getenv('TWITTER_BEARER_TOKEN')
        
        if not self.bearer_token:
            raise ValueError(
                "Bearer token manquant. D√©finissez TWITTER_BEARER_TOKEN dans .env"
            )
        
        # Initialiser le client Tweepy avec gestion des rate limits
        self.client = tweepy.Client(
            bearer_token=self.bearer_token,
            wait_on_rate_limit=True  # Attendre automatiquement si limite atteinte
        )
        
        # Requ√™te de recherche pour Tesla
        # Recherche : Tesla, TSLA, @Tesla, Elon Musk (exclut les retweets)
        self.query = "(Tesla OR TSLA OR @Tesla OR \"Elon Musk\") -is:retweet lang:en"
    
    def _save_incremental(self, tweets_data: List[Dict], output_file: str, existing_ids: set):
        """
        Sauvegarde incr√©mentale des tweets pour √©viter la perte de donn√©es.
        """
        if not tweets_data:
            return
        
        df_new = pd.DataFrame(tweets_data)
        
        # Charger les donn√©es existantes ou cr√©er un nouveau DataFrame
        if os.path.exists(output_file):
            try:
                df_existing = pd.read_csv(output_file)
                df_combined = pd.concat([df_existing, df_new], ignore_index=True)
                # Supprimer les doublons bas√©s sur l'ID
                df_combined = df_combined.drop_duplicates(subset=['id'], keep='last')
            except:
                df_combined = df_new
        else:
            df_combined = df_new
        
        # Sauvegarder
        os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)
        df_combined.to_csv(output_file, index=False, encoding='utf-8')
        
    def collect_tweets(
        self, 
        max_tweets: int = 500,
        output_file: str = "data/tesla_tweets_raw.csv"
    ) -> pd.DataFrame:
        """
        Collecte les tweets r√©cents sur Tesla.
        
        Args:
            max_tweets: Nombre maximum de tweets √† collecter (d√©faut: 500)
            output_file: Chemin du fichier CSV de sortie
            
        Returns:
            DataFrame pandas contenant les tweets collect√©s
        """
        print(f"üîç Collecte de {max_tweets} tweets sur Tesla...")
        print(f"‚è≥ Note: Avec l'API Essential, cela peut prendre plusieurs cycles de rate limit (15 min chacun)")
        print(f"   Le script attendra automatiquement et continuera jusqu'√† atteindre {max_tweets} tweets.\n")
        
        tweets_data = []
        tweet_count = 0
        
        # Charger les tweets existants si le fichier existe d√©j√†
        if os.path.exists(output_file):
            try:
                existing_df = pd.read_csv(output_file)
                tweet_count = len(existing_df)
                print(f"üìÇ {tweet_count} tweets d√©j√† collect√©s, reprise de la collecte...")
                # Charger les IDs existants pour √©viter les doublons
                existing_ids = set(existing_df['id'].astype(str))
            except:
                existing_ids = set()
        else:
            existing_ids = set()
        
        try:
            # Utiliser search_recent_tweets pour l'API v2 (gratuite Essential)
            # max_results par requ√™te limit√© √† 100 (maximum autoris√©)
            for tweet in tweepy.Paginator(
                self.client.search_recent_tweets,
                query=self.query,
                tweet_fields=['created_at', 'public_metrics', 'author_id', 'text'],
                user_fields=['username', 'name'],
                expansions=['author_id'],
                max_results=100,  # Maximum par requ√™te
                limit=((max_tweets // 100) + 1)  # Nombre de pages n√©cessaires
            ).flatten(limit=max_tweets):
                
                # √âviter les doublons
                tweet_id_str = str(tweet.id)
                if tweet_id_str in existing_ids:
                    continue
                
                # Extraire les m√©triques publiques
                metrics = tweet.public_metrics
                
                # Cr√©er un dictionnaire avec les donn√©es du tweet
                tweet_dict = {
                    'id': tweet.id,
                    'date': tweet.created_at,
                    'text': tweet.text,
                    'user_id': tweet.author_id,
                    'likes': metrics.get('like_count', 0),
                    'retweets': metrics.get('retweet_count', 0),
                    'replies': metrics.get('reply_count', 0),
                    'quotes': metrics.get('quote_count', 0)
                }
                
                tweets_data.append(tweet_dict)
                existing_ids.add(tweet_id_str)
                tweet_count += 1
                
                # Sauvegarder p√©riodiquement (tous les 10 tweets)
                if len(tweets_data) >= 10:
                    self._save_incremental(tweets_data, output_file, existing_ids)
                    tweets_data = []  # R√©initialiser apr√®s sauvegarde
                
                # Afficher la progression tous les 10 tweets
                if tweet_count % 10 == 0:
                    print(f"   ‚úÖ {tweet_count}/{max_tweets} tweets collect√©s ({tweet_count*100//max_tweets}%)...")
                
                # Arr√™ter si on a atteint le maximum
                if tweet_count >= max_tweets:
                    break
            
            # Sauvegarder les tweets restants
            if tweets_data:
                self._save_incremental(tweets_data, output_file, existing_ids)
            
            print(f"‚úÖ Collecte termin√©e : {tweet_count} tweets collect√©s")
            
        except tweepy.TooManyRequests:
            print("‚ùå Erreur : Trop de requ√™tes. Attente automatique...")
            time.sleep(60)
            return self.collect_tweets(max_tweets, output_file)
            
        except tweepy.Unauthorized:
            raise ValueError("‚ùå Erreur d'authentification. V√©rifiez votre bearer token.")
            
        except tweepy.BadRequest as e:
            raise ValueError(f"‚ùå Requ√™te invalide : {e}")
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la collecte : {e}")
            raise
        
        # Cr√©er le DataFrame
        df = pd.DataFrame(tweets_data)
        
        # R√©cup√©rer les usernames (n√©cessite une requ√™te suppl√©mentaire)
        if len(df) > 0 and 'user_id' in df.columns:
            try:
                user_ids = df['user_id'].unique().tolist()
                users = self.client.get_users(ids=user_ids, user_fields=['username', 'name'])
                
                # Cr√©er un mapping user_id -> username
                if users.data:
                    user_map = {user.id: user.username for user in users.data}
                    df['user'] = df['user_id'].map(user_map).fillna('unknown')
                else:
                    df['user'] = 'unknown'
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Impossible de r√©cup√©rer les usernames : {e}")
                df['user'] = 'unknown'
        
        # R√©organiser les colonnes pour la sortie
        columns_order = ['id', 'date', 'text', 'user', 'likes', 'retweets', 'replies', 'quotes']
        df = df[[col for col in columns_order if col in df.columns]]
        
        # S'assurer qu'on a exactement max_tweets (500) et supprimer les doublons par ID
        df = df.drop_duplicates(subset=['id'], keep='first')
        
        # Limiter √† max_tweets si on en a plus
        if len(df) > max_tweets:
            print(f"‚ö†Ô∏è  {len(df)} tweets collect√©s, limitation √† {max_tweets} tweets")
            df = df.head(max_tweets)
        
        # Sauvegarder en CSV
        os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)
        df.to_csv(output_file, index=False, encoding='utf-8')
        print(f"üíæ {len(df)} tweets uniques sauvegard√©s dans {output_file} (limite: {max_tweets})")
        
        return df
    
    def test_connection(self) -> bool:
        """
        Teste la connexion √† l'API Twitter.
        
        Returns:
            True si la connexion fonctionne, False sinon
        """
        try:
            # Faire une requ√™te test pour v√©rifier l'authentification
            test_query = "Tesla -is:retweet lang:en"
            response = self.client.search_recent_tweets(
                query=test_query,
                max_results=10
            )
            print("‚úÖ Connexion √† l'API Twitter r√©ussie")
            return True
            
        except tweepy.Unauthorized as e:
            print(f"‚ùå Erreur d'authentification (401 Unauthorized)")
            print(f"   Le Bearer Token est invalide, expir√© ou mal configur√©.")
            print(f"   V√©rifiez votre fichier .env et assurez-vous que :")
            print(f"   1. TWITTER_BEARER_TOKEN contient un token valide")
            print(f"   2. Le token commence par 'AAAAAA' ou 'Bearer AAAAAA'")
            print(f"   3. Le token n'est pas expir√© (g√©n√©rez-en un nouveau si n√©cessaire)")
            print(f"   4. Pas d'espaces ou guillemets autour du token dans .env")
            return False
        except Exception as e:
            print(f"‚ùå Erreur de connexion : {e}")
            return False


def main():
    """
    Fonction principale pour ex√©cuter la collecte.
    """
    try:
        # Initialiser le collecteur
        collector = TeslaTweetCollector()
        
        # Tester la connexion
        if not collector.test_connection():
            print("‚ùå Impossible de se connecter √† l'API Twitter")
            return
        
        # Collecter 500 tweets (ou moins pour un test rapide)
        # Pour un test rapide, utilisez max_tweets=100
        max_tweets = int(os.getenv('MAX_TWEETS', '500'))
        df_tweets = collector.collect_tweets(max_tweets=max_tweets)
        
        # Afficher un aper√ßu
        print("\nüìä Aper√ßu des donn√©es collect√©es :")
        print(df_tweets.head())
        print(f"\nüìà Statistiques :")
        print(f"   Total tweets : {len(df_tweets)}")
        print(f"   P√©riode : {df_tweets['date'].min()} √† {df_tweets['date'].max()}")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ex√©cution : {e}")
        raise


if __name__ == "__main__":
    main()

