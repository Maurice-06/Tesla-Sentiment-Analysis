"""
Phase 2 - NLP : Analyse de sentiment des tweets Tesla

Ce module analyse le sentiment des tweets nettoyÃ©s en utilisant VADER
(adaptÃ© aux rÃ©seaux sociaux) et TextBlob (pour comparaison).
Classification : Positif (>0.1), NÃ©gatif (<-0.1), Neutre (sinon)
"""

import pandas as pd
import numpy as np
from nltk.sentiment import SentimentIntensityAnalyzer
from textblob import TextBlob
import nltk
import os
from typing import Dict, List, Tuple

# TÃ©lÃ©charger VADER lexicon si nÃ©cessaire
try:
    nltk.data.find('vader_lexicon')
except LookupError:
    nltk.download('vader_lexicon', quiet=True)


class TeslaSentimentAnalyzer:
    """
    Classe pour analyser le sentiment des tweets Tesla.
    
    Utilise VADER (adaptÃ© aux rÃ©seaux sociaux) et TextBlob pour comparer.
    """
    
    def __init__(self):
        """
        Initialise les analyseurs de sentiment.
        """
        # Initialiser VADER (Valence Aware Dictionary and sEntiment Reasoner)
        # VADER est spÃ©cialement conÃ§u pour les textes des rÃ©seaux sociaux
        self.vader_analyzer = SentimentIntensityAnalyzer()
        
        print("âœ… Analyseurs de sentiment initialisÃ©s (VADER + TextBlob)")
    
    def analyze_with_vader(self, text: str) -> Dict[str, float]:
        """
        Analyse le sentiment avec VADER.
        
        Args:
            text: Texte Ã  analyser
            
        Returns:
            Dictionnaire avec les scores de polaritÃ© VADER
        """
        if pd.isna(text) or text == '':
            return {
                'compound': 0.0,
                'pos': 0.0,
                'neu': 0.0,
                'neg': 0.0
            }
        
        scores = self.vader_analyzer.polarity_scores(str(text))
        return scores
    
    def analyze_with_textblob(self, text: str) -> Dict[str, float]:
        """
        Analyse le sentiment avec TextBlob.
        
        Args:
            text: Texte Ã  analyser
            
        Returns:
            Dictionnaire avec les scores de polaritÃ© TextBlob
        """
        if pd.isna(text) or text == '':
            return {
                'polarity': 0.0,
                'subjectivity': 0.0
            }
        
        blob = TextBlob(str(text))
        return {
            'polarity': blob.sentiment.polarity,  # Entre -1 et 1
            'subjectivity': blob.sentiment.subjectivity  # Entre 0 et 1
        }
    
    def classify_sentiment(self, polarity: float) -> str:
        """
        Classifie le sentiment selon le barÃ¨me :
        - Positif : polaritÃ© > 0.1
        - NÃ©gatif : polaritÃ© < -0.1
        - Neutre : sinon
        
        Args:
            polarity: Score de polaritÃ© (gÃ©nÃ©ralement entre -1 et 1)
            
        Returns:
            'positive', 'negative' ou 'neutral'
        """
        if polarity > 0.1:
            return 'positive'
        elif polarity < -0.1:
            return 'negative'
        else:
            return 'neutral'
    
    def analyze_dataframe(self, df: pd.DataFrame, text_column: str = 'text_cleaned') -> pd.DataFrame:
        """
        Analyse le sentiment pour tous les tweets du DataFrame.
        
        Args:
            df: DataFrame avec les tweets nettoyÃ©s
            text_column: Nom de la colonne contenant le texte nettoyÃ©
            
        Returns:
            DataFrame avec les colonnes d'analyse de sentiment ajoutÃ©es
        """
        print(f"ğŸ“Š Analyse de sentiment pour {len(df)} tweets...")
        
        df_analyzed = df.copy()
        
        # Analyse avec VADER
        print("   ğŸ” Analyse VADER en cours...")
        vader_scores = df_analyzed[text_column].apply(self.analyze_with_vader)
        
        df_analyzed['vader_compound'] = [s['compound'] for s in vader_scores]
        df_analyzed['vader_pos'] = [s['pos'] for s in vader_scores]
        df_analyzed['vader_neu'] = [s['neu'] for s in vader_scores]
        df_analyzed['vader_neg'] = [s['neg'] for s in vader_scores]
        
        # Classification avec VADER (utilise compound score)
        df_analyzed['sentiment_vader'] = df_analyzed['vader_compound'].apply(self.classify_sentiment)
        
        # Analyse avec TextBlob (pour comparaison)
        print("   ğŸ” Analyse TextBlob en cours...")
        textblob_scores = df_analyzed[text_column].apply(self.analyze_with_textblob)
        
        df_analyzed['textblob_polarity'] = [s['polarity'] for s in textblob_scores]
        df_analyzed['textblob_subjectivity'] = [s['subjectivity'] for s in textblob_scores]
        
        # Classification avec TextBlob
        df_analyzed['sentiment_textblob'] = df_analyzed['textblob_polarity'].apply(self.classify_sentiment)
        
        # Utiliser VADER comme classification principale (plus adaptÃ© aux rÃ©seaux sociaux)
        df_analyzed['sentiment'] = df_analyzed['sentiment_vader']
        df_analyzed['polarity'] = df_analyzed['vader_compound']
        
        print("âœ… Analyse de sentiment terminÃ©e")
        
        return df_analyzed
    
    def get_top_negative_tweets(self, df: pd.DataFrame, n: int = 5) -> pd.DataFrame:
        """
        Identifie les N tweets les plus nÃ©gatifs.
        
        Args:
            df: DataFrame avec les scores de sentiment
            n: Nombre de tweets Ã  retourner (dÃ©faut: 5)
            
        Returns:
            DataFrame avec les N tweets les plus nÃ©gatifs
        """
        # Trier par polaritÃ© croissante (plus nÃ©gatif en premier)
        top_negative = df.nsmallest(n, 'polarity')
        
        return top_negative[['id', 'date', 'text', 'text_cleaned', 'polarity', 
                           'sentiment', 'vader_neg', 'likes', 'retweets']]
    
    def get_statistics(self, df: pd.DataFrame) -> Dict:
        """
        Calcule les statistiques globales de sentiment.
        
        Args:
            df: DataFrame avec les scores de sentiment
            
        Returns:
            Dictionnaire avec les statistiques
        """
        total = len(df)
        
        sentiment_counts = df['sentiment'].value_counts()
        
        stats = {
            'total_tweets': total,
            'positive_count': sentiment_counts.get('positive', 0),
            'negative_count': sentiment_counts.get('negative', 0),
            'neutral_count': sentiment_counts.get('neutral', 0),
            'positive_percent': (sentiment_counts.get('positive', 0) / total) * 100,
            'negative_percent': (sentiment_counts.get('negative', 0) / total) * 100,
            'neutral_percent': (sentiment_counts.get('neutral', 0) / total) * 100,
            'mean_polarity': df['polarity'].mean(),
            'std_polarity': df['polarity'].std(),
            'mean_subjectivity': df['textblob_subjectivity'].mean()
        }
        
        return stats
    
    def detect_sarcasm_indicators(self, text: str) -> List[str]:
        """
        DÃ©tecte des indicateurs potentiels de sarcasme dans le texte.
        
        Note: Cette fonction est basique et pourrait Ãªtre amÃ©liorÃ©e avec
        des modÃ¨les de deep learning fine-tunÃ©s.
        
        Args:
            text: Texte Ã  analyser
            
        Returns:
            Liste des indicateurs dÃ©tectÃ©s
        """
        if pd.isna(text) or text == '':
            return []
        
        text_lower = str(text).lower()
        indicators = []
        
        # Mots-clÃ©s souvent associÃ©s au sarcasme
        sarcasm_keywords = [
            'yeah right', 'as if', 'sure', 'obviously', 'totally',
            'great job', 'brilliant', 'perfect', 'wonderful'
        ]
        
        # Emojis sarcastiques (simplifiÃ©)
        sarcasm_patterns = [
            'ğŸ™„', 'ğŸ˜’', 'ğŸ˜', '/s'  # /s est souvent utilisÃ© pour indiquer le sarcasme
        ]
        
        for keyword in sarcasm_keywords:
            if keyword in text_lower:
                indicators.append(f"Mot-clÃ© sarcastique: '{keyword}'")
        
        for pattern in sarcasm_patterns:
            if pattern in text:
                indicators.append(f"Pattern sarcastique: '{pattern}'")
        
        return indicators


def main():
    """
    Fonction principale pour exÃ©cuter l'analyse de sentiment.
    """
    input_file = "data/tesla_tweets_cleaned.csv"
    output_file = "data/tesla_sentiment_results.csv"
    
    # VÃ©rifier que le fichier d'entrÃ©e existe
    if not os.path.exists(input_file):
        print(f"âŒ Fichier introuvable : {input_file}")
        print("   Veuillez d'abord exÃ©cuter preprocess_tesla.py")
        return
    
    # Charger les donnÃ©es nettoyÃ©es
    print(f"ğŸ“‚ Chargement des donnÃ©es depuis {input_file}...")
    df_cleaned = pd.read_csv(input_file)
    print(f"   {len(df_cleaned)} tweets chargÃ©s")
    
    # Initialiser l'analyseur
    analyzer = TeslaSentimentAnalyzer()
    
    # Analyser le sentiment
    df_analyzed = analyzer.analyze_dataframe(df_cleaned)
    
    # Obtenir les statistiques
    stats = analyzer.get_statistics(df_analyzed)
    
    print("\nğŸ“ˆ Statistiques de sentiment :")
    print(f"   Total tweets : {stats['total_tweets']}")
    print(f"   Positifs : {stats['positive_count']} ({stats['positive_percent']:.1f}%)")
    print(f"   NÃ©gatifs : {stats['negative_count']} ({stats['negative_percent']:.1f}%)")
    print(f"   Neutres : {stats['neutral_count']} ({stats['neutral_percent']:.1f}%)")
    print(f"   PolaritÃ© moyenne : {stats['mean_polarity']:.3f}")
    
    # Identifier les 5 tweets les plus nÃ©gatifs
    print("\nğŸ” Identification des 5 tweets les plus nÃ©gatifs...")
    top_negative = analyzer.get_top_negative_tweets(df_analyzed, n=5)
    
    print("\nğŸ“‹ Top 5 tweets les plus nÃ©gatifs :")
    for idx, row in top_negative.iterrows():
        print(f"\n   Tweet #{idx}:")
        print(f"   PolaritÃ©: {row['polarity']:.3f}")
        print(f"   Score nÃ©gatif VADER: {row['vader_neg']:.3f}")
        print(f"   Texte: {row['text'][:150]}...")
        
        # DÃ©tecter le sarcasme
        sarcasm_indicators = analyzer.detect_sarcasm_indicators(row['text'])
        if sarcasm_indicators:
            print(f"   âš ï¸  Indicateurs de sarcasme dÃ©tectÃ©s: {', '.join(sarcasm_indicators)}")
    
    # Sauvegarder les rÃ©sultats
    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)
    df_analyzed.to_csv(output_file, index=False, encoding='utf-8')
    print(f"\nğŸ’¾ RÃ©sultats sauvegardÃ©s dans {output_file}")


if __name__ == "__main__":
    main()

