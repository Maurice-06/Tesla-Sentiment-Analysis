{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1 & 2 - Data Engineering & NLP : Pr√©traitement et Analyse de Sentiment\n",
        "\n",
        "Ce notebook d√©montre :\n",
        "1. Le nettoyage des tweets collect√©s\n",
        "2. L'analyse de sentiment avec VADER et TextBlob\n",
        "3. La classification des sentiments\n",
        "4. L'identification des tweets les plus n√©gatifs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importation des biblioth√®ques\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
        "\n",
        "from src.preprocess_tesla import TeslaTextPreprocessor\n",
        "from src.analyze_tesla_sentiment import TeslaSentimentAnalyzer\n",
        "\n",
        "print(\"‚úÖ Biblioth√®ques import√©es\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## √âtape 1 : Chargement des donn√©es brutes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger les donn√©es brutes\n",
        "df_raw = pd.read_csv(\"../data/tesla_tweets_raw.csv\")\n",
        "print(f\"üìä {len(df_raw)} tweets charg√©s\")\n",
        "\n",
        "# Afficher un exemple de tweet brut\n",
        "print(\"\\nüìù Exemple de tweet brut :\")\n",
        "print(df_raw['text'].iloc[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## √âtape 2 : Pr√©traitement des tweets\n",
        "\n",
        "Le pr√©traitement effectue les op√©rations suivantes :\n",
        "- Suppression des liens HTTP/HTTPS\n",
        "- Suppression des mentions @user\n",
        "- Suppression de la ponctuation et des chiffres\n",
        "- Conversion en minuscules\n",
        "- Suppression des stopwords\n",
        "- Extraction de features sp√©cifiques √† Tesla\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialiser le preprocessor\n",
        "preprocessor = TeslaTextPreprocessor(language='english', lemmatize=False)\n",
        "\n",
        "# Nettoyer les tweets\n",
        "df_cleaned = preprocessor.preprocess_dataframe(df_raw)\n",
        "\n",
        "# Comparer avant/apr√®s\n",
        "print(\"\\nüîç Comparaison avant/apr√®s nettoyage :\\n\")\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Avant': df_raw['text'].head(3).values,\n",
        "    'Apr√®s': df_cleaned['text_cleaned'].head(3).values\n",
        "})\n",
        "comparison_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sauvegarder les donn√©es nettoy√©es\n",
        "df_cleaned.to_csv(\"../data/tesla_tweets_cleaned.csv\", index=False)\n",
        "print(\"üíæ Donn√©es nettoy√©es sauvegard√©es\")\n",
        "\n",
        "# Statistiques sur les features Tesla\n",
        "print(\"\\nüìà Features Tesla extraites :\")\n",
        "print(f\"   Tweets mentionnant un mod√®le : {df_cleaned['mentions_model'].sum()}\")\n",
        "print(f\"   Tweets mentionnant Elon Musk : {df_cleaned['mentions_elon'].sum()}\")\n",
        "print(f\"   Tweets mentionnant la compagnie : {df_cleaned['mentions_company'].sum()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## √âtape 3 : Analyse de sentiment\n",
        "\n",
        "Nous utilisons deux m√©thodes :\n",
        "- **VADER** : Sp√©cialement con√ßu pour les r√©seaux sociaux\n",
        "- **TextBlob** : M√©thode classique bas√©e sur des r√®gles\n",
        "\n",
        "**Classification :**\n",
        "- Positif : polarit√© > 0.1\n",
        "- N√©gatif : polarit√© < -0.1\n",
        "- Neutre : -0.1 ‚â§ polarit√© ‚â§ 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialiser l'analyseur\n",
        "analyzer = TeslaSentimentAnalyzer()\n",
        "\n",
        "# Analyser le sentiment\n",
        "df_analyzed = analyzer.analyze_dataframe(df_cleaned)\n",
        "\n",
        "# Afficher un aper√ßu\n",
        "print(\"\\nüìä Aper√ßu des r√©sultats d'analyse :\")\n",
        "df_analyzed[['text_cleaned', 'polarity', 'sentiment', 'vader_compound', 'textblob_polarity']].head(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistiques globales\n",
        "stats = analyzer.get_statistics(df_analyzed)\n",
        "\n",
        "print(\"üìà Statistiques de sentiment :\")\n",
        "print(f\"   Total tweets : {stats['total_tweets']}\")\n",
        "print(f\"   Positifs : {stats['positive_count']} ({stats['positive_percent']:.1f}%)\")\n",
        "print(f\"   N√©gatifs : {stats['negative_count']} ({stats['negative_percent']:.1f}%)\")\n",
        "print(f\"   Neutres : {stats['neutral_count']} ({stats['neutral_percent']:.1f}%)\")\n",
        "print(f\"   Polarit√© moyenne : {stats['mean_polarity']:.3f} ¬± {stats['std_polarity']:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## √âtape 4 : Visualisation de la distribution des sentiments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graphique en barres de la distribution\n",
        "sentiment_counts = df_analyzed['sentiment'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "colors = {'positive': '#2E7D32', 'negative': '#C62828', 'neutral': '#757575'}\n",
        "bars = plt.bar(sentiment_counts.index.str.title(), sentiment_counts.values, \n",
        "               color=[colors.get(s.lower(), '#757575') for s in sentiment_counts.index])\n",
        "\n",
        "plt.title('Distribution des Sentiments', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Sentiment', fontsize=12)\n",
        "plt.ylabel('Nombre de tweets', fontsize=12)\n",
        "\n",
        "# Ajouter les valeurs sur les barres\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{int(height)}\\n({height/len(df_analyzed)*100:.1f}%)',\n",
        "             ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histogramme de la distribution des polarit√©s\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.hist(df_analyzed['polarity'], bins=50, edgecolor='black', alpha=0.7, color='#E31937')\n",
        "plt.axvline(x=0.1, color='green', linestyle='--', label='Seuil positif (>0.1)')\n",
        "plt.axvline(x=-0.1, color='red', linestyle='--', label='Seuil n√©gatif (<-0.1)')\n",
        "plt.axvline(x=0, color='gray', linestyle='-', alpha=0.3)\n",
        "plt.title('Distribution des Scores de Polarit√©', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Polarit√©', fontsize=12)\n",
        "plt.ylabel('Fr√©quence', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## √âtape 5 : Comparaison VADER vs TextBlob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparaison des classifications\n",
        "comparison = pd.crosstab(df_analyzed['sentiment_vader'], df_analyzed['sentiment_textblob'], \n",
        "                         margins=True, margins_name=\"Total\")\n",
        "\n",
        "print(\"üìä Matrice de confusion VADER vs TextBlob :\")\n",
        "print(comparison)\n",
        "\n",
        "# Visualisation\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(comparison.iloc[:-1, :-1], annot=True, fmt='d', cmap='YlOrRd', \n",
        "            cbar_kws={'label': 'Nombre de tweets'})\n",
        "plt.title('Comparaison des Classifications VADER vs TextBlob', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('TextBlob', fontsize=12)\n",
        "plt.ylabel('VADER', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## √âtape 6 : Identification des tweets les plus n√©gatifs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtenir les 5 tweets les plus n√©gatifs\n",
        "top_negative = analyzer.get_top_negative_tweets(df_analyzed, n=5)\n",
        "\n",
        "print(\"üî¥ Top 5 tweets les plus n√©gatifs :\\n\")\n",
        "for idx, (_, row) in enumerate(top_negative.iterrows(), 1):\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Tweet #{idx} - Polarit√©: {row['polarity']:.3f}\")\n",
        "    print(f\"Score n√©gatif VADER: {row['vader_neg']:.3f}\")\n",
        "    print(f\"Likes: {row.get('likes', 0)} | RT: {row.get('retweets', 0)}\")\n",
        "    print(f\"\\nTexte original :\\n{row['text']}\")\n",
        "    print(f\"\\nTexte nettoy√© :\\n{row['text_cleaned']}\")\n",
        "    \n",
        "    # D√©tecter le sarcasme\n",
        "    sarcasm_indicators = analyzer.detect_sarcasm_indicators(row['text'])\n",
        "    if sarcasm_indicators:\n",
        "        print(f\"\\n‚ö†Ô∏è  Indicateurs de sarcasme : {', '.join(sarcasm_indicators)}\")\n",
        "    print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sauvegarder les r√©sultats finaux\n",
        "df_analyzed.to_csv(\"../data/tesla_sentiment_results.csv\", index=False)\n",
        "print(\"üíæ R√©sultats d'analyse sauvegard√©s dans ../data/tesla_sentiment_results.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "‚úÖ **Pr√©traitement et analyse termin√©s !**\n",
        "\n",
        "- ‚úÖ Tweets nettoy√©s et pr√©trait√©s\n",
        "- ‚úÖ Analyse de sentiment effectu√©e avec VADER et TextBlob\n",
        "- ‚úÖ Classification des sentiments (Positif/N√©gatif/Neutre)\n",
        "- ‚úÖ Identification des tweets les plus n√©gatifs\n",
        "- ‚úÖ Donn√©es sauvegard√©es pour le dashboard\n",
        "\n",
        "**Prochaine √©tape** : Utiliser le dashboard Streamlit (`python src/tesla_dashboard.py`) ou le notebook `3_visualize_dashboard.ipynb` pour visualiser les r√©sultats.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
