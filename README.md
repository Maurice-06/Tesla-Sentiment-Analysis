# üöó Analyse de Sentiment sur les R√©seaux Sociaux - Projet Tesla

Projet acad√©mique d'analyse de sentiment sur les tweets concernant la marque Tesla, utilisant l'API Twitter, le traitement du langage naturel (NLP) et des outils de visualisation.

## üìã Table des Mati√®res

- [Description](#description)
- [Architecture du Projet](#architecture-du-projet)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Structure des Donn√©es](#structure-des-donn√©es)
- [Livrables](#livrables)

## üìù Description

Ce projet comprend trois phases principales :

1. **Data Engineering** : Collecte et pr√©paration des donn√©es

   - Collecte de 500 tweets r√©cents sur Tesla via l'API Twitter v2
   - Nettoyage des donn√©es (liens, mentions, ponctuation, etc.)

2. **NLP - Analyse de Sentiment** : Traitement du langage naturel

   - Analyse de sentiment avec VADER (sp√©cialis√© r√©seaux sociaux) et TextBlob
   - Classification : Positif (>0.1), N√©gatif (<-0.1), Neutre (sinon)
   - Identification des 5 tweets les plus n√©gatifs
   - D√©tection basique de sarcasme

3. **Business Intelligence** : Visualisation et Dashboard

   - Dashboard interactif Streamlit
   - Graphique camembert des sentiments
   - WordCloud des tweets n√©gatifs
   - Histogrammes temporels
   - Analyse des tweets probl√©matiques

   üìñ **Documentation d√©taill√©e** : Voir [PHASE3_DASHBOARD.md](PHASE3_DASHBOARD.md) pour plus d'informations sur le dashboard.

## üèóÔ∏è Architecture du Projet

```
tesla_sentiment_analysis/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ tesla_tweets_raw.csv          # Tweets bruts collect√©s
‚îÇ   ‚îú‚îÄ‚îÄ tesla_tweets_cleaned.csv      # Tweets nettoy√©s
‚îÇ   ‚îî‚îÄ‚îÄ tesla_sentiment_results.csv   # R√©sultats d'analyse
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ collect_tesla_tweets.py       # Phase 1 : Collecte Twitter
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_tesla.py           # Phase 1 : Nettoyage
‚îÇ   ‚îú‚îÄ‚îÄ analyze_tesla_sentiment.py    # Phase 2 : Analyse NLP
‚îÇ   ‚îî‚îÄ‚îÄ tesla_dashboard.py            # Phase 3 : Dashboard Streamlit
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 1_collect_tweets.ipynb        # Notebook collecte
‚îÇ   ‚îú‚îÄ‚îÄ 2_preprocess_analyze.ipynb    # Notebook nettoyage & analyse
‚îÇ   ‚îî‚îÄ‚îÄ 3_visualize_dashboard.ipynb   # Notebook visualisation
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                  # D√©pendances Python
‚îú‚îÄ‚îÄ .env.example                      # Exemple de configuration
‚îú‚îÄ‚îÄ .gitignore                        # Fichiers √† ignorer
‚îú‚îÄ‚îÄ README.md                         # Ce fichier
‚îî‚îÄ‚îÄ rapport_limites.md                # Rapport d'analyse et limites
```

## üöÄ Installation

### Pr√©requis

- Python 3.8 ou sup√©rieur
- Compte d√©veloppeur Twitter avec acc√®s √† l'API (niveau Essential gratuit)
- Git (optionnel)

### √âtapes d'installation

1. **Cloner le projet** (ou t√©l√©charger les fichiers)

```bash
git clone <url-du-repo>
cd tesla_sentiment_analysis
```

2. **Cr√©er un environnement virtuel** (recommand√©)

```bash
python -m venv venv

# Sur macOS/Linux
source venv/bin/activate

# Sur Windows
venv\Scripts\activate
```

3. **Installer les d√©pendances**

```bash
pip install -r requirements.txt
```

4. **T√©l√©charger les ressources NLTK** (automatique lors de la premi√®re ex√©cution, ou manuellement) :

```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('vader_lexicon')
```

## ‚öôÔ∏è Configuration

### Configuration

#### Option A : API Twitter (Tweepy)

1. **Obtenir les credentials Twitter** :

   - Cr√©er un compte d√©veloppeur sur [developer.twitter.com](https://developer.twitter.com)
   - Cr√©er une application et obtenir un Bearer Token (API v2 Essential)

2. **Configurer les variables d'environnement** :

Copiez `env.example.txt` vers `.env` et remplissez vos credentials :

```bash
cp env.example.txt .env
```

√âditez `.env` :

```env
# Twitter API v2 (Essential Access)
TWITTER_BEARER_TOKEN=votre_bearer_token_ici
```

#### Option B : snscrape (Alternative sans API)

**Pas de configuration n√©cessaire !** snscrape fonctionne sans authentification.

```bash
# Installer snscrape
pip install snscrape

# Utiliser le script alternatif
python src/collect_tesla_tweets_snscrape.py
```

**Recommand√© si** :

- Votre quota API Twitter est √©puis√©
- Vous voulez √©viter les limites de l'API
- Vous pr√©f√©rez une solution sans authentification

**‚ö†Ô∏è Important** : Ne commitez jamais le fichier `.env` ! Il est d√©j√† dans `.gitignore`.

## üìñ Utilisation

### M√©thode 1 : Ex√©cution via scripts Python

#### √âtape 1 : Collecte des tweets

**Option A : Avec l'API Twitter (Tweepy)** - N√©cessite un Bearer Token

```bash
python src/collect_tesla_tweets.py
```

Ce script va :

- Se connecter √† l'API Twitter
- Collecter 500 tweets r√©cents sur Tesla
- Sauvegarder dans `data/tesla_tweets_raw.csv`

**Note** : N√©cessite un Bearer Token valide et respecte les quotas de l'API.

**Option B : Avec snscrape (Recommand√© si quota API √©puis√©)** - Sans authentification

```bash
# Installer snscrape d'abord
pip install snscrape

# Collecter les tweets
python src/collect_tesla_tweets_snscrape.py
```

Ce script va :

- Utiliser snscrape (pas de quota API)
- Collecter 500 tweets r√©cents sur Tesla
- Sauvegarder dans `data/tesla_tweets_raw.csv`

**Avantages de snscrape** :

- ‚úÖ Pas de quota API
- ‚úÖ Pas d'authentification n√©cessaire
- ‚úÖ Acc√®s aux m√™mes donn√©es publiques

**Note** : snscrape peut √™tre plus lent que l'API officielle mais fonctionne sans limite.

#### √âtape 2 : Nettoyage des donn√©es

```bash
python src/preprocess_tesla.py
```

Ce script va :

- Charger les tweets bruts
- Nettoyer le texte (liens, mentions, ponctuation, etc.)
- Extraire des features sp√©cifiques √† Tesla
- Sauvegarder dans `data/tesla_tweets_cleaned.csv`

#### √âtape 3 : Analyse de sentiment

```bash
python src/analyze_tesla_sentiment.py
```

Ce script va :

- Analyser le sentiment avec VADER et TextBlob
- Classifier les tweets (Positif/N√©gatif/Neutre)
- Identifier les 5 tweets les plus n√©gatifs
- Sauvegarder dans `data/tesla_sentiment_results.csv`

#### √âtape 4 : Dashboard interactif

**üé® Dashboard Moderne - FastAPI + Tailwind CSS**

```bash
# Rendre le script ex√©cutable (premi√®re fois seulement)
chmod +x run_dashboard.sh

# Lancer le dashboard
./run_dashboard.sh
```

**üåê Acc√®s au Dashboard**

Le dashboard s'ouvrira automatiquement dans votre navigateur √† :

- **URL locale** : `http://localhost:8000`
- **URL r√©seau** : `http://[votre-ip]:8000` (pour acc√®s depuis d'autres appareils)

**Fonctionnalit√©s du Dashboard :**

- üé® **Design √©pur√©** : Interface moderne avec Tailwind CSS
- üìä **Graphiques interactifs** : Chart.js pour des visualisations fluides
- ‚òÅÔ∏è **WordCloud** : Mots les plus fr√©quents dans les tweets n√©gatifs
- üìÖ **Histogramme temporel** : Volume de tweets par jour
- üî¥ **Top 5 tweets n√©gatifs** : Analyse d√©taill√©e avec design en cards
- üîç **Filtres interactifs** : Par sentiment et par p√©riode avec mise √† jour en temps r√©el
- üìà **M√©triques en temps r√©el** : Cards avec ic√¥nes et animations
- ‚ö° **Performance optimale** : API RESTful FastAPI

üìñ **Documentation compl√®te** : Voir [DASHBOARD_MODERNE.md](DASHBOARD_MODERNE.md)

**Note** : Le dashboard fonctionne avec les fichiers `tesla_sentiment_results.csv` ou `tesla_sentiment_analysis.csv` dans le dossier `data/`.

### M√©thode 2 : Utilisation des notebooks Jupyter

Les notebooks fournissent une approche p√©dagogique √©tape par √©tape :

1. **`notebooks/1_collect_tweets.ipynb`** : Collecte des tweets
2. **`notebooks/2_preprocess_analyze.ipynb`** : Nettoyage et analyse
3. **`notebooks/3_visualize_dashboard.ipynb`** : Visualisations

Pour lancer Jupyter :

```bash
jupyter notebook
# ou
jupyter lab
```

## üìä Structure des Donn√©es

### Fichier `tesla_tweets_raw.csv`

Colonnes :

- `id` : ID unique du tweet
- `date` : Date de publication
- `text` : Texte brut du tweet
- `user` : Nom d'utilisateur
- `likes` : Nombre de likes
- `retweets` : Nombre de retweets
- `replies` : Nombre de r√©ponses
- `quotes` : Nombre de citations

### Fichier `tesla_tweets_cleaned.csv`

Colonnes suppl√©mentaires :

- `text_cleaned` : Texte nettoy√©
- `mentions_model` : Bool√©en (mention d'un mod√®le Tesla)
- `mentions_company` : Bool√©en (mention de la compagnie)
- `mentions_elon` : Bool√©en (mention d'Elon Musk)
- `mentioned_models` : Liste des mod√®les mentionn√©s

### Fichier `tesla_sentiment_results.csv`

Colonnes suppl√©mentaires :

- `vader_compound` : Score compound VADER (-1 √† 1)
- `vader_pos`, `vader_neu`, `vader_neg` : Scores VADER d√©taill√©s
- `textblob_polarity` : Polarit√© TextBlob (-1 √† 1)
- `textblob_subjectivity` : Subjectivit√© TextBlob (0 √† 1)
- `sentiment` : Classification finale (positive/negative/neutral)
- `polarity` : Score de polarit√© utilis√© pour la classification

## üì¶ Livrables

- ‚úÖ Code Python modulaire et document√©
- ‚úÖ 3 notebooks Jupyter p√©dagogiques
- ‚úÖ Dashboard moderne interactif (FastAPI + Tailwind CSS)
- ‚úÖ Rapport d'analyse et limites (`rapport_limites.md`)
- ‚úÖ Documentation compl√®te (ce README)
- ‚úÖ **500 tweets analys√©s** (limite respect√©e avec suppression des doublons)

## üîß Technologies Utilis√©es

- **Python 3.8+**
- **Tweepy 4.14** : Interface API Twitter
- **NLTK** : Traitement du langage naturel
- **VADER** : Analyseur de sentiment pour r√©seaux sociaux
- **TextBlob** : Analyse de sentiment bas√©e sur des r√®gles
- **Pandas** : Manipulation de donn√©es
- **Matplotlib/Seaborn** : Visualisation
- **WordCloud** : Nuages de mots
- **Streamlit** : Dashboard interactif
- **Plotly** : Graphiques interactifs

## ‚ö†Ô∏è Limitations et Am√©liorations

Consultez le fichier `rapport_limites.md` pour une analyse d√©taill√©e des :

- Difficult√©s rencontr√©es avec l'API Twitter
- Limites des algorithmes VADER/TextBlob
- Probl√®me de d√©tection du sarcasme
- Am√©liorations possibles (BERT, mod√®les fine-tun√©s)
- Biais potentiels dans l'analyse

## üìÑ Licence

Ce projet est r√©alis√© dans un contexte acad√©mique.

## üë§ Auteur

Projet acad√©mique - Analyse de Sentiment sur les R√©seaux Sociaux

## üôè Remerciements

- API Twitter pour l'acc√®s aux donn√©es
- Communaut√©s open-source Python pour les biblioth√®ques utilis√©es
